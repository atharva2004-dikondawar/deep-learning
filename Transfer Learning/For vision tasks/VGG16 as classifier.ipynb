{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "852fae61-f45f-4ec8-b545-56fbb7f2169b",
   "metadata": {},
   "source": [
    "## Pre-Trained Model as Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943f5379-6d3c-43b6-b9b5-7bf102f9cde2",
   "metadata": {},
   "source": [
    "A pre-trained model can be used directly to classify new photographs as one of the 1,000 known classes in the image classification task in the ILSVRC.\n",
    "\n",
    "We will use the VGG16 model to classify new images.\n",
    "\n",
    "First, the photograph needs to loaded and reshaped to a 224×224 square, expected by the model, and the pixel values scaled in the way expected by the model. The model operates on an array of samples, therefore the dimensions of a loaded image need to be expanded by 1, for one image with 224×224 pixels and three channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e36c7ce3-3d86-45b3-bd29-f44f62445cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467096/553467096 [==============================] - 55s 0us/step\n",
      "1/1 [==============================] - 0s 425ms/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
      "35363/35363 [==============================] - 0s 0us/step\n",
      "Doberman (36.74%)\n"
     ]
    }
   ],
   "source": [
    "# example of using a pre-trained model as a classifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "# load an image from file\n",
    "image = load_img('dog.jpg', target_size=(224, 224))\n",
    "\n",
    "# convert the image pixels to a numpy array\n",
    "image = img_to_array(image)\n",
    "\n",
    "# reshape data for the model\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "\n",
    "# prepare the image for the VGG model\n",
    "image = preprocess_input(image)\n",
    "\n",
    "# load the model\n",
    "model = VGG16()\n",
    "\n",
    "# predict the probability across all output classes\n",
    "yhat = model.predict(image)\n",
    "\n",
    "# convert the probabilities to class labels\n",
    "label = decode_predictions(yhat)\n",
    "\n",
    "# retrieve the most likely result, e.g. highest probability\n",
    "label = label[0][0]\n",
    "\n",
    "# print the classification\n",
    "print('%s (%.2f%%)' % (label[1], label[2]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2a93a73-b566-4dcd-a007-492fa7b4d6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('n02107142', 'Doberman', 0.36742732), ('n02105412', 'kelpie', 0.19215928), ('n02106550', 'Rottweiler', 0.17119955), ('n02089078', 'black-and-tan_coonhound', 0.11455941), ('n02107312', 'miniature_pinscher', 0.045257583)]]\n"
     ]
    }
   ],
   "source": [
    "label = decode_predictions(yhat)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42974260-12a4-41a7-a390-c5559e5e3944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('n02107142', 'Doberman', 0.36742732)\n"
     ]
    }
   ],
   "source": [
    "label = label[0][0]\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249b9850-bfe6-44e8-9b5c-66f34b4e942f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dlenv)",
   "language": "python",
   "name": "dlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
